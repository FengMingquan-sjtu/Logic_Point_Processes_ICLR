start optimize:
Head = C, base = -0.2000
Rule0: A --> C , A BEFORE C, weight=1.0000
Finish screening one variable, the log likelihood is -10.050344572665361
Params  [tensor([0.0601], dtype=torch.float64, requires_grad=True), tensor([0.5171], dtype=torch.float64, requires_grad=True)]
Current rule is: A --> C , A BEFORE C
feature sum is tensor(4.3651, dtype=torch.float64)
log-likelihood is  -10.050344572665361
weight = 0.5171064749113963
base = 0.060138821381584315
start optimize using cp:
----
log-likelihood-CP is  -10.048887361747392
weight= [0.4422456]
base= [0.06074428]
-------------
start optimize:
Head = C, base = 0.0601
Rule0: A --> C , A EQUAL C, weight=1.0000
Finish screening one variable, the log likelihood is -10.194385147890214
Params  [tensor([0.0401], dtype=torch.float64, requires_grad=True), tensor([0.0617], dtype=torch.float64, requires_grad=True)]
Current rule is: A --> C , A EQUAL C
feature sum is tensor(-5.6635, dtype=torch.float64)
log-likelihood is  -10.194385147890214
weight = 0.06171498188500277
base = 0.040096456552421805
start optimize using cp:
----
log-likelihood-CP is  -10.182558191332824
weight= [0.0526222]
base= [0.05684435]
-------------
This rule is filtered, feature_sum=0,  A --> C , A AFTER C
-------------
start optimize:
Head = C, base = 0.0401
Rule0: B --> C , B BEFORE C, weight=1.0000
Finish screening one variable, the log likelihood is -10.089871465850008
Params  [tensor([0.0820], dtype=torch.float64, requires_grad=True), tensor([0.3214], dtype=torch.float64, requires_grad=True)]
Current rule is: B --> C , B BEFORE C
feature sum is tensor(-1.4670, dtype=torch.float64)
log-likelihood is  -10.089871465850008
weight = 0.32139617649669483
base = 0.08198519524827631
start optimize using cp:
----
log-likelihood-CP is  -10.077641961943597
weight= [0.2531108]
base= [0.06010749]
-------------
start optimize:
Head = C, base = 0.0820
Rule0: B --> C , B EQUAL C, weight=1.0000
Finish screening one variable, the log likelihood is -10.197326559218165
Params  [tensor([0.0575], dtype=torch.float64, requires_grad=True), tensor([0.0632], dtype=torch.float64, requires_grad=True)]
Current rule is: B --> C , B EQUAL C
feature sum is tensor(-0.0600, dtype=torch.float64)
log-likelihood is  -10.197326559218165
weight = 0.06320128411942331
base = 0.05750195507815695
start optimize using cp:
----
log-likelihood-CP is  -10.18096117907532
weight= [0.08919107]
base= [0.05663329]
-------------
This rule is filtered, feature_sum=0,  B --> C , B AFTER C
-------------
start optimize:
Head = C, base = 0.0575
Rule0: Not A --> C , Not A BEFORE C, weight=1.0000
Finish screening one variable, the log likelihood is -10.13546733154468
Params  [tensor([0.0551], dtype=torch.float64, requires_grad=True), tensor([0.3274], dtype=torch.float64, requires_grad=True)]
Current rule is: Not A --> C , Not A BEFORE C
feature sum is tensor(0.0889, dtype=torch.float64)
log-likelihood is  -10.13546733154468
weight = 0.3273876898187705
base = 0.055075103602636115
start optimize using cp:
----
log-likelihood-CP is  -10.145346725702181
weight= [0.26407871]
base= [0.06106998]
-------------
start optimize:
Head = C, base = 0.0551
Rule0: Not A --> C , Not A EQUAL C, weight=1.0000
Finish screening one variable, the log likelihood is -10.188204643121924
Params  [tensor([0.0674], dtype=torch.float64, requires_grad=True), tensor([0.2021], dtype=torch.float64, requires_grad=True)]
Current rule is: Not A --> C , Not A EQUAL C
feature sum is tensor(-1.0799, dtype=torch.float64)
log-likelihood is  -10.188204643121924
weight = 0.20211114194936486
base = 0.06738587031341904
start optimize using cp:
----
log-likelihood-CP is  -10.174890496886025
weight= [0.27540548]
base= [0.05652512]
-------------
This rule is filtered, feature_sum=0,  Not A --> C , Not A AFTER C
-------------
start optimize:
Head = C, base = 0.0674
Rule0: Not B --> C , Not B BEFORE C, weight=1.0000
