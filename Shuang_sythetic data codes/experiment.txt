run (fit data-2, worker_num=16, iter_num=5) setsid python3 logic_learning_2.py  1>out-2.txt 2>err-2.txt at Mar1, 16:37

run (fit data-2 multiprocess likelihood, batch_size_mp=64) setsid python3 logic_learning_2.py 1>out-3.txt 2>err-3.txt, at Mar4,9:38
run (generate data-2 with time-window=10, add feature filter) setsid python3 generate_synthetic_data.py 1>out-1.txt 2>err-1.txt at Mar5, 20:29
run (generate data-2 with time-window=10) setsid python3 generate_synthetic_data.py 1>out-.txt 2>err-.txt at Mar5, 19:34

run setsid python3 generate_synthetic_data.py at Mar6,16:53, generate 100 samples for data-4
run setsid python3 generate_synthetic_data.py at Mar6,16:57, generate 2000 samples for data-4

at Mar6,21:35-21:36, fit 320,640,1280 samples of data-4
at Mar7,10:02-10:05, fit 2560,1280,640 samples of data-4. remove fix of bug#73, and set rule_num to 20.
at Mar7,23:10 re-generate data-4
at Mar7,23:32, re-generate simple data-4 fit 1280,640 samples of data-4. 
at Mar8,10:27-28, tune hyper-params,  fit data-4 2560,1280,640, samples. 
at Mar8,15:36-41, tune hyper-params,  fit data-4 2560,1280,640, samples. 
at Mar8,17:09 use cp(ecos solver), fit 320 samples
at Mar8,17:54 use cp(mosek solver, single thread), fit 320 samples
at Mar8,17:58 use cp(mosek solver, 8 thread), fit 320 samples

at Mar8,20:08-09 use cp(mosek solver, single thread), fit 320,640,1280 samples

at Mar9,13:20 use cp(mosek), fit 320 samples, start from Rule6
at Mar9,15:27 use cp(mosek), fit 320 samples, start from Null.
at Mar9,20:47 use cp(scs), fit 320 samples, start from Null.
at Mar9,20:58 use cp(mosek), fit 320 samples, start from Null.

at Mar10,18:53 use cp(mosek), fix unbounded bug, fit 320 samples, start from Null.

at Mar10,23:21 use cp(mosek),  fit data-4, 640 samples, start from Null.

at Mar10,23:30 use cp(mosek), fit data-4, 1280 samples, start from Null.

at Mar11, 10:42, use torch, fit data-4, 2560 samples, start from Null. promising result.
at Mar11, 16:31, use torch, fit data-4, 1200 samples, start from Null. 
at Mar11, 18:15, use torch, modify rule-set=15, worker_num=12, fit data-4, 1200 samples, start from Null. promising reuslt.
at Mar11, 19:23, use torch, modify rule-set=15, worker_num=12, fit data-4, 600 samples, start from Null.
at Mar11, 20:24, use torch, modify rule-set=15, worker_num=12, fit data-4, 2400 samples, start from Null.

at Mar12, 10:19, use DFS, torch, worker_num=12, num_iter=12, fit data-4, 600 samples
at Mar12, 11:09, use DFS, torch, worker_num=12, num_iter=6, fit data-4, 1200 samples
at Mar12, 11:12, use DFS, torch, worker_num=12, num_iter=3, fit data-4, 2400 samples

data-4{
at Mar12, 15:22, 15:22, 15:25 use BFS, torch, worker_num=12, num_iter=12, fit data-4, 600,1200,2400 samples
at Mar12, 15:52, 15:56, 15:59, fit GT rules, torch, worker_num=12, num_iter=50, data-4, 600, 1200, 2400 samples.
at Mar13, 10:29, use DFS, torch, worker_num=12, num_iter=12, fit data-4, 600,1200,2400 samples
}

data-5{
at Mar12, 16:27, generate data-5. data-5 has same rule set with data-4, but w=0.5 
at Mar12, 16:28, fit GT rules, torch, worker_num=12, num_iter=50, data-5, 600,1200,2400 samples.
at Mar12, 17:01, use DFS and BFS, torch, worker_num=12, num_iter=12, fit data-5, 600,1200,2400 samples
at Mar13, 09:56, tune prune-weights, use DFS and BFS, torch, worker_num=12, num_iter=12, fit data-5, 600,1200,2400 samples

}

data-6{
at Mar12, 16:36, generate data-6. data-6 has same rule set with data-4, but w=1.5 
                fit GT rules, torch, worker_num=12, num_iter=50, data-6, 600,1200,2400 samples.
at Mar12, 23:37, use DFS and BFS, torch, worker_num=12, num_iter=12, fit data-6, 600,1200,2400 samples
at Mar13, 09:55, tune prune-weights, use DFS and BFS, torch, worker_num=12, num_iter=12, fit data-6, 600,1200,2400 samples

}

