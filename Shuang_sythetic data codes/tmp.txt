-----key model information----
num_formula=0
time_window=10
Time_tolerance=1
integral_resolution=0.5
decay_rate=0.1
batch_size=1
num_batch_check_for_feature=1
num_batch_check_for_gradient=20
num_batch_no_update_limit_opt=300
num_iter=1
num_iter_final=1
epsilon=0.003
gain_threshold=0.001
low_grad_threshold=0.001
low_grad_tolerance=2
weight_threshold=0.001
strict_weight_threshold=0.002
learning_rate=0.001
max_rule_body_length=1
max_num_rule=20
batch_size_cp=500
batch_size_grad=1
use_cp=False
worker_num=10
best_N=1
static_pred_coef=1
debug_mode=True
use_exp_kernel=True
----
---- start optimize_log_likelihood multi-process----
Rule set is:
Head:A, base=-0.1000,
use 1 workers for 1 batches
[Debug mode] Use SGD
Before batch_idx= 0
param-0=tensor([-0.1000], dtype=torch.float64)
grad-0= None
intensity_log_sum= tensor(-0.6000, dtype=torch.float64, grad_fn=<SumBackward0>)
intensity_integral= tensor(2.2621, dtype=torch.float64, grad_fn=<SumBackward0>)
log_likelihood= tensor([-2.8621], dtype=torch.float64, grad_fn=<AddBackward0>)
After batch_idx= 0
param-0=tensor([-0.0963], dtype=torch.float64)
grad-0=tensor([-3.7379], dtype=torch.float64)
param-0=tensor([-0.0963], dtype=torch.float64)
grad-0=tensor([-3.7379], dtype=torch.float64)
optimized rule weights are:
Head:A, base=-0.0963,
---- exit optimize_log_likelihood multi-process----
log-likelihood= -2.8620935506598135
[initial optimize] Elapsed: 0.1197 sec.
----- start BFS -----
----- start generate_rule_via_column_generation -----
---start calculate intensity grad and integral grad.---
use 1 workers, run 1 data
[calculate intensity grad and integral grad] Elapsed: 0.0043 sec.
---exit calculate intensity grad and integral grad.---
start enumerating candidate rules.
----- start select_and_add_new_rule -----
-------start multiprocess------
cpu num = 48, use 2 workers, process 2 candidate rules.
rule is :  A --> A , A EQUAL A
feature at t=0.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.1 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.1 is tensor([1.9702], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.9 is tensor([2.7419], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.0 is tensor([0.8958], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.0 is tensor([2.8088], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.1 is tensor([1.7828], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.1 is tensor([2.8751], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.0 is tensor([0.8958], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.0 is tensor([2.8088], dtype=torch.float64)
[multiprocess log-grad] Elapsed: 0.1099 sec.
-------end multiprocess------
------Select N best rule-------
log-likelihood-grad(all-data) mean= 8.36503, std=nan, Rule = A --> A , A EQUAL A
-------------
log-likelihood-grad(all-data) mean= 2.27178, std=nan, Rule = A --> A , A BEFORE A
-------------
Best rule is: A --> A , A EQUAL A
Best log-likelihood-grad(all-data) = 8.36503223410804
new rule added.
---- start optimize_log_likelihood multi-process----
Rule set is:
Head:A, base=-0.0963,
Rule0: A --> A , A EQUAL A, weight=0.0100,
use 1 workers for 1 batches
[Debug mode] Use SGD
Before batch_idx= 0
param-0=tensor([-0.0963], dtype=torch.float64)
grad-0= None
param-1=tensor([0.0100], dtype=torch.float64)
grad-1= None
rule is :  A --> A , A EQUAL A
feature at t=0.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.1 is tensor([1.9702], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.9 is tensor([2.7419], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.0 is tensor([2.8088], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.1 is tensor([2.8751], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.0 is tensor([2.8088], dtype=torch.float64)
intensity_log_sum= tensor(-0.4637, dtype=torch.float64, grad_fn=<SumBackward0>)
intensity_integral= tensor(2.3012, dtype=torch.float64, grad_fn=<SumBackward0>)
log_likelihood= tensor([-2.7649], dtype=torch.float64, grad_fn=<AddBackward0>)
After batch_idx= 0
param-0=tensor([-0.0926], dtype=torch.float64)
grad-0=tensor([-3.6988], dtype=torch.float64)
param-1=tensor([0.0183], dtype=torch.float64)
grad-1=tensor([-8.2867], dtype=torch.float64)
param-0=tensor([-0.0926], dtype=torch.float64)
grad-0=tensor([-3.6988], dtype=torch.float64)
param-1=tensor([0.0183], dtype=torch.float64)
grad-1=tensor([-8.2867], dtype=torch.float64)
optimized rule weights are:
Head:A, base=-0.0926,
Rule0: A --> A , A EQUAL A, weight=0.0183,
---- exit optimize_log_likelihood multi-process----
[optimize log-likelihood (torch)] Elapsed: 0.2178 sec.
Update Log-likelihood (torch)=  -2.7648769504301107
Added rule and re-fitted weights. Current rule set is:
Head:A, base(torch) = -0.0926,
Rule0: A --> A , A EQUAL A, weight(torch)=0.0183,
----- exit select_and_add_new_rule -----
----- exit generate_rule_via_column_generation -----
----- start generation -----
cpu num = 48, use 1 workers, generate 1 samples.
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.0 is tensor([2.8088], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=3.0 is tensor([1.8188], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.9392854178670583 is tensor([0.9961], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.1224027649038204 is tensor([1.9658], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.3668741027349727 is tensor([2.8920], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.205720158922947 is tensor([0.9699], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.3788138474534657 is tensor([1.9161], dtype=torch.float64)
[multiprocess generation] Elapsed: 0.0127 sec.
MAE = 0.1834628751130337
----- exit generation -----
----- start generate_rule_via_column_generation -----
---start calculate intensity grad and integral grad.---
use 1 workers, run 1 data
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
[calculate intensity grad and integral grad] Elapsed: 0.0029 sec.
---exit calculate intensity grad and integral grad.---
start enumerating candidate rules.
----- start select_and_add_new_rule -----
-------start multiprocess------
cpu num = 48, use 1 workers, process 1 candidate rules.
rule is :  A --> A , A BEFORE A
feature at t=0.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.1 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.0 is tensor([0.8958], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.5 is tensor([0.], dtype=torch.float64)
[multiprocess log-grad] Elapsed: 0.0041 sec.
-------end multiprocess------
------Select N best rule-------
log-likelihood-grad(all-data) mean= 0.89583, std=nan, Rule = A --> A , A BEFORE A
-------------
Best rule is: A --> A , A BEFORE A
Best log-likelihood-grad(all-data) = 0.8958341352965282
new rule added.
---- start optimize_log_likelihood multi-process----
Rule set is:
Head:A, base=-0.0926,
Rule0: A --> A , A EQUAL A, weight=0.0183,
Rule1: A --> A , A BEFORE A, weight=0.0100,
use 1 workers for 1 batches
[Debug mode] Use SGD
Before batch_idx= 0
param-0=tensor([-0.0926], dtype=torch.float64)
grad-0= None
param-1=tensor([0.0183], dtype=torch.float64)
grad-1= None
param-2=tensor([0.0100], dtype=torch.float64)
grad-2= None
rule is :  A --> A , A EQUAL A
feature at t=0.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.1 is tensor([1.9702], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.1 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.9 is tensor([2.7419], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.0 is tensor([2.8088], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.0 is tensor([0.8958], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.5 is tensor([0.], dtype=torch.float64)
intensity_log_sum= tensor(-0.2982, dtype=torch.float64, grad_fn=<SumBackward0>)
intensity_integral= tensor(1.8559, dtype=torch.float64, grad_fn=<SumBackward0>)
log_likelihood= tensor([-2.1541], dtype=torch.float64, grad_fn=<AddBackward0>)
After batch_idx= 0
param-0=tensor([-0.0894], dtype=torch.float64)
grad-0=tensor([-3.1441], dtype=torch.float64)
param-1=tensor([0.0250], dtype=torch.float64)
grad-1=tensor([-6.6811], dtype=torch.float64)
param-2=tensor([0.0109], dtype=torch.float64)
grad-2=tensor([-0.8958], dtype=torch.float64)
param-0=tensor([-0.0894], dtype=torch.float64)
grad-0=tensor([-3.1441], dtype=torch.float64)
param-1=tensor([0.0250], dtype=torch.float64)
grad-1=tensor([-6.6811], dtype=torch.float64)
param-2=tensor([0.0109], dtype=torch.float64)
grad-2=tensor([-0.8958], dtype=torch.float64)
optimized rule weights are:
Head:A, base=-0.0894,
Rule0: A --> A , A EQUAL A, weight=0.0250,
Rule1: A --> A , A BEFORE A, weight=0.0109,
---- exit optimize_log_likelihood multi-process----
[optimize log-likelihood (torch)] Elapsed: 0.1133 sec.
Update Log-likelihood (torch)=  -2.154147960652524
Added rule and re-fitted weights. Current rule set is:
Head:A, base(torch) = -0.0894,
Rule0: A --> A , A EQUAL A, weight(torch)=0.0250,
Rule1: A --> A , A BEFORE A, weight(torch)=0.0109,
----- exit select_and_add_new_rule -----
----- exit generate_rule_via_column_generation -----
----- start generation -----
cpu num = 48, use 1 workers, generate 1 samples.
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.0 is tensor([2.8088], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.0 is tensor([0.8958], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.5 is tensor([1.8930], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.5 is tensor([2.5822], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5493379713577105 is tensor([1.8837], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.5493379713577105 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.7871093108452296 is tensor([0.9151], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.7871093108452296 is tensor([2.5091], dtype=torch.float64)
[multiprocess generation] Elapsed: 0.0622 sec.
MAE = 0.867289456440588
----- exit generation -----
----- start generate_rule_via_column_generation -----
---start calculate intensity grad and integral grad.---
use 1 workers, run 1 data
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.5 is tensor([0.], dtype=torch.float64)
[calculate intensity grad and integral grad] Elapsed: 0.0041 sec.
---exit calculate intensity grad and integral grad.---
start enumerating candidate rules.
----- start select_and_add_new_rule -----
No candidate rule generated.
----- exit select_and_add_new_rule -----
----- exit generate_rule_via_column_generation -----
BFS finished, rule set is:
Head:A, base(torch) = -0.0894,
Rule0: A --> A , A EQUAL A, weight(torch)=0.0250,
Rule1: A --> A , A BEFORE A, weight(torch)=0.0109,
----- start final_tune -----
---- start optimize_log_likelihood multi-process----
Rule set is:
Head:A, base=-0.0894,
Rule0: A --> A , A EQUAL A, weight=0.0250,
Rule1: A --> A , A BEFORE A, weight=0.0109,
use 1 workers for 1 batches
[Debug mode] Use SGD
Before batch_idx= 0
param-0=tensor([-0.0894], dtype=torch.float64)
grad-0= None
param-1=tensor([0.0250], dtype=torch.float64)
grad-1= None
param-2=tensor([0.0109], dtype=torch.float64)
grad-2= None
rule is :  A --> A , A EQUAL A
feature at t=0.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.1 is tensor([1.9702], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.1 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.9 is tensor([2.7419], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.9 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.5 is tensor([0.], dtype=torch.float64)
intensity_log_sum= tensor(-0.2153, dtype=torch.float64, grad_fn=<SumBackward0>)
intensity_integral= tensor(1.8741, dtype=torch.float64, grad_fn=<SumBackward0>)
log_likelihood= tensor([-2.0894], dtype=torch.float64, grad_fn=<AddBackward0>)
After batch_idx= 0
param-0=tensor([-0.0873], dtype=torch.float64)
grad-0=tensor([-2.1259], dtype=torch.float64)
param-1=tensor([0.0288], dtype=torch.float64)
grad-1=tensor([-3.8370], dtype=torch.float64)
param-2=tensor([0.0109], dtype=torch.float64)
grad-2=tensor([0.], dtype=torch.float64)
param-0=tensor([-0.0873], dtype=torch.float64)
grad-0=tensor([-2.1259], dtype=torch.float64)
param-1=tensor([0.0288], dtype=torch.float64)
grad-1=tensor([-3.8370], dtype=torch.float64)
param-2=tensor([0.0109], dtype=torch.float64)
grad-2=tensor([0.], dtype=torch.float64)
optimized rule weights are:
Head:A, base=-0.0873,
Rule0: A --> A , A EQUAL A, weight=0.0288,
Rule1: A --> A , A BEFORE A, weight=0.0109,
---- exit optimize_log_likelihood multi-process----
final_tune finished, rule set is:
Head:A, base(torch) = -0.0873,
Rule0: A --> A , A EQUAL A, weight(torch)=0.0288,
Rule1: A --> A , A BEFORE A, weight(torch)=0.0109,
----- exit final_tune -----
----- start generation -----
cpu num = 48, use 1 workers, generate 1 samples.
rule is :  A --> A , A EQUAL A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=0.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.0 is tensor([0.9900], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.0 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.5 is tensor([2.8538], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.5 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.0 is tensor([2.8088], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.0 is tensor([0.8958], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=2.5 is tensor([0.9418], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=2.5 is tensor([2.5822], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.8756638342644267 is tensor([0.9070], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.8756638342644267 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.3461843220068856 is tensor([1.9223], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.3461843220068856 is tensor([0.], dtype=torch.float64)
rule is :  A --> A , A EQUAL A
feature at t=1.3773691964541717 is tensor([2.8890], dtype=torch.float64)
rule is :  A --> A , A BEFORE A
feature at t=1.3773691964541717 is tensor([0.], dtype=torch.float64)
[multiprocess generation] Elapsed: 0.0101 sec.
MAE = 0.41111973995428513
----- exit generation -----
----- exit BFS -----
