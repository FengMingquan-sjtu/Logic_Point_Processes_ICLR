start train
total weight  5381
training deep net... [1/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 43058.16 | apl: 6.35
building surrogate dataset...
training surrogate net... [1/12]
model: mlp | iter: 0 | loss: 34.78
model: mlp | iter: 250 | loss: 4.81
model: mlp | iter: 500 | loss: 3.27
model: mlp | iter: 750 | loss: 3.02
model: mlp | iter: 1000 | loss: 2.95
model: mlp | iter: 1250 | loss: 2.92
model: mlp | iter: 1500 | loss: 2.91
model: mlp | iter: 1750 | loss: 2.90
model: mlp | iter: 2000 | loss: 2.89
model: mlp | iter: 2250 | loss: 2.88
model: mlp | iter: 2500 | loss: 2.88
model: mlp | iter: 2750 | loss: 2.87
model: mlp | iter: 3000 | loss: 2.87
model: mlp | iter: 3250 | loss: 2.87
model: mlp | iter: 3500 | loss: 2.86
model: mlp | iter: 3750 | loss: 2.86
model: mlp | iter: 4000 | loss: 2.86
model: mlp | iter: 4250 | loss: 2.86
model: mlp | iter: 4500 | loss: 2.86
model: mlp | iter: 4750 | loss: 2.86
training deep net... [2/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 42477.76 | apl: 5.57
building surrogate dataset...
training surrogate net... [2/12]
model: mlp | iter: 0 | loss: 31.20
model: mlp | iter: 250 | loss: 4.35
model: mlp | iter: 500 | loss: 2.95
model: mlp | iter: 750 | loss: 2.76
model: mlp | iter: 1000 | loss: 2.71
model: mlp | iter: 1250 | loss: 2.70
model: mlp | iter: 1500 | loss: 2.69
model: mlp | iter: 1750 | loss: 2.69
model: mlp | iter: 2000 | loss: 2.68
model: mlp | iter: 2250 | loss: 2.68
model: mlp | iter: 2500 | loss: 2.67
model: mlp | iter: 2750 | loss: 2.67
model: mlp | iter: 3000 | loss: 2.67
model: mlp | iter: 3250 | loss: 2.66
model: mlp | iter: 3500 | loss: 2.66
model: mlp | iter: 3750 | loss: 2.66
model: mlp | iter: 4000 | loss: 2.66
model: mlp | iter: 4250 | loss: 2.66
model: mlp | iter: 4500 | loss: 2.66
model: mlp | iter: 4750 | loss: 2.66
training deep net... [3/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 41490.19 | apl: 5.59
building surrogate dataset...
training surrogate net... [3/12]
model: mlp | iter: 0 | loss: 32.33
model: mlp | iter: 250 | loss: 4.77
model: mlp | iter: 500 | loss: 3.21
model: mlp | iter: 750 | loss: 2.95
model: mlp | iter: 1000 | loss: 2.89
model: mlp | iter: 1250 | loss: 2.87
model: mlp | iter: 1500 | loss: 2.86
model: mlp | iter: 1750 | loss: 2.85
model: mlp | iter: 2000 | loss: 2.84
model: mlp | iter: 2250 | loss: 2.83
model: mlp | iter: 2500 | loss: 2.82
model: mlp | iter: 2750 | loss: 2.81
model: mlp | iter: 3000 | loss: 2.80
model: mlp | iter: 3250 | loss: 2.80
model: mlp | iter: 3500 | loss: 2.80
model: mlp | iter: 3750 | loss: 2.79
model: mlp | iter: 4000 | loss: 2.79
model: mlp | iter: 4250 | loss: 2.79
model: mlp | iter: 4500 | loss: 2.79
model: mlp | iter: 4750 | loss: 2.79
training deep net... [4/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 40409.76 | apl: 5.59
building surrogate dataset...
training surrogate net... [4/12]
model: mlp | iter: 0 | loss: 30.94
model: mlp | iter: 250 | loss: 4.75
model: mlp | iter: 500 | loss: 3.29
model: mlp | iter: 750 | loss: 3.04
model: mlp | iter: 1000 | loss: 2.97
model: mlp | iter: 1250 | loss: 2.95
model: mlp | iter: 1500 | loss: 2.93
model: mlp | iter: 1750 | loss: 2.92
model: mlp | iter: 2000 | loss: 2.92
model: mlp | iter: 2250 | loss: 2.91
model: mlp | iter: 2500 | loss: 2.91
model: mlp | iter: 2750 | loss: 2.90
model: mlp | iter: 3000 | loss: 2.90
model: mlp | iter: 3250 | loss: 2.89
model: mlp | iter: 3500 | loss: 2.89
model: mlp | iter: 3750 | loss: 2.89
model: mlp | iter: 4000 | loss: 2.89
model: mlp | iter: 4250 | loss: 2.89
model: mlp | iter: 4500 | loss: 2.89
model: mlp | iter: 4750 | loss: 2.89
training deep net... [5/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 39264.16 | apl: 5.59
building surrogate dataset...
training surrogate net... [5/12]
model: mlp | iter: 0 | loss: 31.85
model: mlp | iter: 250 | loss: 5.09
model: mlp | iter: 500 | loss: 3.41
model: mlp | iter: 750 | loss: 3.10
model: mlp | iter: 1000 | loss: 3.04
model: mlp | iter: 1250 | loss: 3.02
model: mlp | iter: 1500 | loss: 3.01
model: mlp | iter: 1750 | loss: 3.00
model: mlp | iter: 2000 | loss: 2.99
model: mlp | iter: 2250 | loss: 2.98
model: mlp | iter: 2500 | loss: 2.98
model: mlp | iter: 2750 | loss: 2.97
model: mlp | iter: 3000 | loss: 2.96
model: mlp | iter: 3250 | loss: 2.96
model: mlp | iter: 3500 | loss: 2.96
model: mlp | iter: 3750 | loss: 2.95
model: mlp | iter: 4000 | loss: 2.95
model: mlp | iter: 4250 | loss: 2.95
model: mlp | iter: 4500 | loss: 2.95
model: mlp | iter: 4750 | loss: 2.95
training deep net... [6/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 38059.01 | apl: 5.59
building surrogate dataset...
training surrogate net... [6/12]
model: mlp | iter: 0 | loss: 31.74
model: mlp | iter: 250 | loss: 5.06
model: mlp | iter: 500 | loss: 3.45
model: mlp | iter: 750 | loss: 3.14
model: mlp | iter: 1000 | loss: 3.07
model: mlp | iter: 1250 | loss: 3.05
model: mlp | iter: 1500 | loss: 3.04
model: mlp | iter: 1750 | loss: 3.03
model: mlp | iter: 2000 | loss: 3.02
model: mlp | iter: 2250 | loss: 3.02
model: mlp | iter: 2500 | loss: 3.01
model: mlp | iter: 2750 | loss: 3.00
model: mlp | iter: 3000 | loss: 3.00
model: mlp | iter: 3250 | loss: 2.99
model: mlp | iter: 3500 | loss: 2.99
model: mlp | iter: 3750 | loss: 2.99
model: mlp | iter: 4000 | loss: 2.99
model: mlp | iter: 4250 | loss: 2.98
model: mlp | iter: 4500 | loss: 2.98
model: mlp | iter: 4750 | loss: 2.98
training deep net... [7/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 37023.53 | apl: 5.59
building surrogate dataset...
training surrogate net... [7/12]
model: mlp | iter: 0 | loss: 31.67
model: mlp | iter: 250 | loss: 4.87
model: mlp | iter: 500 | loss: 3.48
model: mlp | iter: 750 | loss: 3.18
model: mlp | iter: 1000 | loss: 3.11
model: mlp | iter: 1250 | loss: 3.09
model: mlp | iter: 1500 | loss: 3.07
model: mlp | iter: 1750 | loss: 3.06
model: mlp | iter: 2000 | loss: 3.05
model: mlp | iter: 2250 | loss: 3.04
model: mlp | iter: 2500 | loss: 3.03
model: mlp | iter: 2750 | loss: 3.02
model: mlp | iter: 3000 | loss: 3.02
model: mlp | iter: 3250 | loss: 3.01
model: mlp | iter: 3500 | loss: 3.01
model: mlp | iter: 3750 | loss: 3.00
model: mlp | iter: 4000 | loss: 3.00
model: mlp | iter: 4250 | loss: 3.00
model: mlp | iter: 4500 | loss: 3.00
model: mlp | iter: 4750 | loss: 3.00
training deep net... [8/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 35953.35 | apl: 5.59
building surrogate dataset...
training surrogate net... [8/12]
model: mlp | iter: 0 | loss: 31.18
model: mlp | iter: 250 | loss: 4.82
model: mlp | iter: 500 | loss: 3.47
model: mlp | iter: 750 | loss: 3.16
model: mlp | iter: 1000 | loss: 3.08
model: mlp | iter: 1250 | loss: 3.06
model: mlp | iter: 1500 | loss: 3.05
model: mlp | iter: 1750 | loss: 3.04
model: mlp | iter: 2000 | loss: 3.03
model: mlp | iter: 2250 | loss: 3.02
model: mlp | iter: 2500 | loss: 3.02
model: mlp | iter: 2750 | loss: 3.01
model: mlp | iter: 3000 | loss: 3.01
model: mlp | iter: 3250 | loss: 3.00
model: mlp | iter: 3500 | loss: 3.00
model: mlp | iter: 3750 | loss: 3.00
model: mlp | iter: 4000 | loss: 3.00
model: mlp | iter: 4250 | loss: 2.99
model: mlp | iter: 4500 | loss: 2.99
model: mlp | iter: 4750 | loss: 2.99
training deep net... [9/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 35021.55 | apl: 5.59
building surrogate dataset...
training surrogate net... [9/12]
model: mlp | iter: 0 | loss: 32.22
model: mlp | iter: 250 | loss: 4.90
model: mlp | iter: 500 | loss: 3.53
model: mlp | iter: 750 | loss: 3.20
model: mlp | iter: 1000 | loss: 3.11
model: mlp | iter: 1250 | loss: 3.07
model: mlp | iter: 1500 | loss: 3.06
model: mlp | iter: 1750 | loss: 3.05
model: mlp | iter: 2000 | loss: 3.04
model: mlp | iter: 2250 | loss: 3.03
model: mlp | iter: 2500 | loss: 3.02
model: mlp | iter: 2750 | loss: 3.01
model: mlp | iter: 3000 | loss: 3.00
model: mlp | iter: 3250 | loss: 3.00
model: mlp | iter: 3500 | loss: 2.99
model: mlp | iter: 3750 | loss: 2.99
model: mlp | iter: 4000 | loss: 2.98
model: mlp | iter: 4250 | loss: 2.98
model: mlp | iter: 4500 | loss: 2.98
model: mlp | iter: 4750 | loss: 2.98
training deep net... [10/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 34147.48 | apl: 5.59
building surrogate dataset...
training surrogate net... [10/12]
model: mlp | iter: 0 | loss: 32.35
model: mlp | iter: 250 | loss: 4.75
model: mlp | iter: 500 | loss: 3.45
model: mlp | iter: 750 | loss: 3.16
model: mlp | iter: 1000 | loss: 3.09
model: mlp | iter: 1250 | loss: 3.06
model: mlp | iter: 1500 | loss: 3.04
model: mlp | iter: 1750 | loss: 3.03
model: mlp | iter: 2000 | loss: 3.02
model: mlp | iter: 2250 | loss: 3.01
model: mlp | iter: 2500 | loss: 3.00
model: mlp | iter: 2750 | loss: 2.99
model: mlp | iter: 3000 | loss: 2.98
model: mlp | iter: 3250 | loss: 2.98
model: mlp | iter: 3500 | loss: 2.97
model: mlp | iter: 3750 | loss: 2.97
model: mlp | iter: 4000 | loss: 2.96
model: mlp | iter: 4250 | loss: 2.96
model: mlp | iter: 4500 | loss: 2.96
model: mlp | iter: 4750 | loss: 2.96
training deep net... [11/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 32918.07 | apl: 5.59
building surrogate dataset...
training surrogate net... [11/12]
model: mlp | iter: 0 | loss: 31.41
model: mlp | iter: 250 | loss: 4.50
model: mlp | iter: 500 | loss: 3.35
model: mlp | iter: 750 | loss: 3.08
model: mlp | iter: 1000 | loss: 3.01
model: mlp | iter: 1250 | loss: 2.99
model: mlp | iter: 1500 | loss: 2.98
model: mlp | iter: 1750 | loss: 2.97
model: mlp | iter: 2000 | loss: 2.97
model: mlp | iter: 2250 | loss: 2.96
model: mlp | iter: 2500 | loss: 2.95
model: mlp | iter: 2750 | loss: 2.95
model: mlp | iter: 3000 | loss: 2.94
model: mlp | iter: 3250 | loss: 2.94
model: mlp | iter: 3500 | loss: 2.94
model: mlp | iter: 3750 | loss: 2.94
model: mlp | iter: 4000 | loss: 2.93
model: mlp | iter: 4250 | loss: 2.93
model: mlp | iter: 4500 | loss: 2.93
model: mlp | iter: 4750 | loss: 2.93
training deep net... [12/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 31645.78 | apl: 5.59
building surrogate dataset...
training surrogate net... [12/12]
model: mlp | iter: 0 | loss: 29.41
model: mlp | iter: 250 | loss: 4.21
model: mlp | iter: 500 | loss: 3.25
model: mlp | iter: 750 | loss: 3.02
model: mlp | iter: 1000 | loss: 2.95
model: mlp | iter: 1250 | loss: 2.94
model: mlp | iter: 1500 | loss: 2.93
model: mlp | iter: 1750 | loss: 2.92
model: mlp | iter: 2000 | loss: 2.92
model: mlp | iter: 2250 | loss: 2.92
model: mlp | iter: 2500 | loss: 2.92
model: mlp | iter: 2750 | loss: 2.91
model: mlp | iter: 3000 | loss: 2.91
model: mlp | iter: 3250 | loss: 2.91
model: mlp | iter: 3500 | loss: 2.91
model: mlp | iter: 3750 | loss: 2.91
model: mlp | iter: 4000 | loss: 2.91
model: mlp | iter: 4250 | loss: 2.91
model: mlp | iter: 4500 | loss: 2.91
model: mlp | iter: 4750 | loss: 2.91
saved visualize pdf and model to ./trained_models_credit
