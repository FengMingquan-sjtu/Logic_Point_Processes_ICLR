start train
training deep net... [1/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 354518.73 | apl: 3847.09
building surrogate dataset...
training surrogate net... [1/12]
model: mlp | iter: 0 | loss: 14302941.50
model: mlp | iter: 250 | loss: 14235435.86
model: mlp | iter: 500 | loss: 14184915.32
model: mlp | iter: 750 | loss: 14135307.54
model: mlp | iter: 1000 | loss: 14086122.40
model: mlp | iter: 1250 | loss: 14037209.93
model: mlp | iter: 1500 | loss: 13988502.95
model: mlp | iter: 1750 | loss: 13939964.88
model: mlp | iter: 2000 | loss: 13891573.27
model: mlp | iter: 2250 | loss: 13843313.12
model: mlp | iter: 2500 | loss: 13795173.84
model: mlp | iter: 2750 | loss: 13747147.61
model: mlp | iter: 3000 | loss: 13699228.52
model: mlp | iter: 3250 | loss: 13651411.98
model: mlp | iter: 3500 | loss: 13603694.35
model: mlp | iter: 3750 | loss: 13556072.77
model: mlp | iter: 4000 | loss: 13508544.92
model: mlp | iter: 4250 | loss: 13461108.93
model: mlp | iter: 4500 | loss: 13413763.30
model: mlp | iter: 4750 | loss: 13366506.81
training deep net... [2/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 352617.41 | apl: 3717.52
building surrogate dataset...
training surrogate net... [2/12]
model: mlp | iter: 0 | loss: 12570834.60
model: mlp | iter: 250 | loss: 12514545.50
model: mlp | iter: 500 | loss: 12466918.35
model: mlp | iter: 750 | loss: 12420331.08
model: mlp | iter: 1000 | loss: 12374212.83
model: mlp | iter: 1250 | loss: 12328390.63
model: mlp | iter: 1500 | loss: 12282787.62
model: mlp | iter: 1750 | loss: 12237362.30
model: mlp | iter: 2000 | loss: 12192089.33
model: mlp | iter: 2250 | loss: 12146951.94
model: mlp | iter: 2500 | loss: 12101938.37
model: mlp | iter: 2750 | loss: 12057040.02
model: mlp | iter: 3000 | loss: 12012250.40
model: mlp | iter: 3250 | loss: 11967564.49
model: mlp | iter: 3500 | loss: 11922978.39
model: mlp | iter: 3750 | loss: 11878489.00
model: mlp | iter: 4000 | loss: 11834093.83
model: mlp | iter: 4250 | loss: 11789790.89
model: mlp | iter: 4500 | loss: 11745578.59
model: mlp | iter: 4750 | loss: 11701455.62
training deep net... [3/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 334478.39 | apl: 2970.40
building surrogate dataset...
training surrogate net... [3/12]
model: mlp | iter: 0 | loss: 4303597.00
model: mlp | iter: 250 | loss: 4266923.93
model: mlp | iter: 500 | loss: 4240164.89
model: mlp | iter: 750 | loss: 4213922.30
model: mlp | iter: 1000 | loss: 4187948.92
model: mlp | iter: 1250 | loss: 4162167.87
model: mlp | iter: 1500 | loss: 4136543.87
model: mlp | iter: 1750 | loss: 4111057.07
model: mlp | iter: 2000 | loss: 4085694.83
model: mlp | iter: 2250 | loss: 4060448.35
model: mlp | iter: 2500 | loss: 4035311.18
model: mlp | iter: 2750 | loss: 4010278.37
model: mlp | iter: 3000 | loss: 3985346.03
model: mlp | iter: 3250 | loss: 3960511.06
model: mlp | iter: 3500 | loss: 3935770.94
model: mlp | iter: 3750 | loss: 3911123.59
model: mlp | iter: 4000 | loss: 3886567.34
model: mlp | iter: 4250 | loss: 3862100.78
model: mlp | iter: 4500 | loss: 3837722.77
model: mlp | iter: 4750 | loss: 3813432.36
training deep net... [4/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 310258.29 | apl: 1306.16
building surrogate dataset...
training surrogate net... [4/12]
model: mlp | iter: 0 | loss: 825714.45
model: mlp | iter: 250 | loss: 811428.39
model: mlp | iter: 500 | loss: 799746.46
model: mlp | iter: 750 | loss: 788376.31
model: mlp | iter: 1000 | loss: 777195.50
model: mlp | iter: 1250 | loss: 766164.60
model: mlp | iter: 1500 | loss: 755264.63
model: mlp | iter: 1750 | loss: 744484.27
model: mlp | iter: 2000 | loss: 733815.85
model: mlp | iter: 2250 | loss: 723253.75
model: mlp | iter: 2500 | loss: 712793.60
model: mlp | iter: 2750 | loss: 702431.91
model: mlp | iter: 3000 | loss: 692165.83
model: mlp | iter: 3250 | loss: 681993.01
model: mlp | iter: 3500 | loss: 671911.48
model: mlp | iter: 3750 | loss: 661919.60
model: mlp | iter: 4000 | loss: 652016.00
model: mlp | iter: 4250 | loss: 642199.53
model: mlp | iter: 4500 | loss: 632469.21
model: mlp | iter: 4750 | loss: 622824.24
training deep net... [5/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 281709.74 | apl: 575.83
building surrogate dataset...
training surrogate net... [5/12]
model: mlp | iter: 0 | loss: 147159.03
model: mlp | iter: 250 | loss: 141138.92
model: mlp | iter: 500 | loss: 136426.97
model: mlp | iter: 750 | loss: 131908.30
model: mlp | iter: 1000 | loss: 127531.48
model: mlp | iter: 1250 | loss: 123278.13
model: mlp | iter: 1500 | loss: 119138.20
model: mlp | iter: 1750 | loss: 115104.93
model: mlp | iter: 2000 | loss: 111173.26
model: mlp | iter: 2250 | loss: 107339.12
model: mlp | iter: 2500 | loss: 103599.18
model: mlp | iter: 2750 | loss: 99950.61
model: mlp | iter: 3000 | loss: 96391.04
model: mlp | iter: 3250 | loss: 92918.39
model: mlp | iter: 3500 | loss: 89530.92
model: mlp | iter: 3750 | loss: 86227.11
model: mlp | iter: 4000 | loss: 83005.65
model: mlp | iter: 4250 | loss: 79865.41
model: mlp | iter: 4500 | loss: 76805.39
model: mlp | iter: 4750 | loss: 73824.75
training deep net... [6/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 251572.55 | apl: 171.59
building surrogate dataset...
training surrogate net... [6/12]
model: mlp | iter: 0 | loss: 11841.10
model: mlp | iter: 250 | loss: 10223.42
model: mlp | iter: 500 | loss: 9054.64
model: mlp | iter: 750 | loss: 8017.11
model: mlp | iter: 1000 | loss: 7089.02
model: mlp | iter: 1250 | loss: 6258.85
model: mlp | iter: 1500 | loss: 5518.04
model: mlp | iter: 1750 | loss: 4859.51
model: mlp | iter: 2000 | loss: 4277.05
model: mlp | iter: 2250 | loss: 3765.08
model: mlp | iter: 2500 | loss: 3318.45
model: mlp | iter: 2750 | loss: 2932.31
model: mlp | iter: 3000 | loss: 2602.02
model: mlp | iter: 3250 | loss: 2323.04
model: mlp | iter: 3500 | loss: 2090.89
model: mlp | iter: 3750 | loss: 1901.09
model: mlp | iter: 4000 | loss: 1749.13
model: mlp | iter: 4250 | loss: 1630.45
model: mlp | iter: 4500 | loss: 1540.43
model: mlp | iter: 4750 | loss: 1474.51
training deep net... [7/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 220716.66 | apl: 65.44
building surrogate dataset...
training surrogate net... [7/12]
model: mlp | iter: 0 | loss: 1437.45
model: mlp | iter: 250 | loss: 955.99
model: mlp | iter: 500 | loss: 693.86
model: mlp | iter: 750 | loss: 521.79
model: mlp | iter: 1000 | loss: 414.53
model: mlp | iter: 1250 | loss: 352.41
model: mlp | iter: 1500 | loss: 319.63
model: mlp | iter: 1750 | loss: 304.16
model: mlp | iter: 2000 | loss: 297.74
model: mlp | iter: 2250 | loss: 283.59
model: mlp | iter: 2500 | loss: 243.71
model: mlp | iter: 2750 | loss: 228.43
model: mlp | iter: 3000 | loss: 177.40
model: mlp | iter: 3250 | loss: 155.04
model: mlp | iter: 3500 | loss: 139.39
model: mlp | iter: 3750 | loss: 111.69
model: mlp | iter: 4000 | loss: 100.23
model: mlp | iter: 4250 | loss: 80.99
model: mlp | iter: 4500 | loss: 72.09
model: mlp | iter: 4750 | loss: 67.90
training deep net... [8/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 190255.12 | apl: 36.78
building surrogate dataset...
training surrogate net... [8/12]
model: mlp | iter: 0 | loss: 532.04
model: mlp | iter: 250 | loss: 268.77
model: mlp | iter: 500 | loss: 150.10
model: mlp | iter: 750 | loss: 97.01
model: mlp | iter: 1000 | loss: 77.10
model: mlp | iter: 1250 | loss: 71.04
model: mlp | iter: 1500 | loss: 69.49
model: mlp | iter: 1750 | loss: 69.07
model: mlp | iter: 2000 | loss: 68.89
model: mlp | iter: 2250 | loss: 68.75
model: mlp | iter: 2500 | loss: 68.05
model: mlp | iter: 2750 | loss: 67.78
model: mlp | iter: 3000 | loss: 66.91
model: mlp | iter: 3250 | loss: 66.44
model: mlp | iter: 3500 | loss: 65.55
model: mlp | iter: 3750 | loss: 64.85
model: mlp | iter: 4000 | loss: 64.19
model: mlp | iter: 4250 | loss: 63.49
model: mlp | iter: 4500 | loss: 62.76
model: mlp | iter: 4750 | loss: 61.97
training deep net... [9/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 171227.49 | apl: 17.93
building surrogate dataset...
training surrogate net... [9/12]
model: mlp | iter: 0 | loss: 392.44
model: mlp | iter: 250 | loss: 183.33
model: mlp | iter: 500 | loss: 107.87
model: mlp | iter: 750 | loss: 82.50
model: mlp | iter: 1000 | loss: 76.03
model: mlp | iter: 1250 | loss: 72.76
model: mlp | iter: 1500 | loss: 67.43
model: mlp | iter: 1750 | loss: 56.51
model: mlp | iter: 2000 | loss: 48.29
model: mlp | iter: 2250 | loss: 42.55
model: mlp | iter: 2500 | loss: 37.56
model: mlp | iter: 2750 | loss: 35.39
model: mlp | iter: 3000 | loss: 34.06
model: mlp | iter: 3250 | loss: 32.76
model: mlp | iter: 3500 | loss: 32.04
model: mlp | iter: 3750 | loss: 31.42
model: mlp | iter: 4000 | loss: 30.82
model: mlp | iter: 4250 | loss: 30.47
model: mlp | iter: 4500 | loss: 30.18
model: mlp | iter: 4750 | loss: 29.93
training deep net... [10/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 156430.31 | apl: 4.54
building surrogate dataset...
training surrogate net... [10/12]
model: mlp | iter: 0 | loss: 183.60
model: mlp | iter: 250 | loss: 46.09
model: mlp | iter: 500 | loss: 18.72
model: mlp | iter: 750 | loss: 14.38
model: mlp | iter: 1000 | loss: 13.75
model: mlp | iter: 1250 | loss: 13.59
model: mlp | iter: 1500 | loss: 13.53
model: mlp | iter: 1750 | loss: 13.50
model: mlp | iter: 2000 | loss: 13.49
model: mlp | iter: 2250 | loss: 13.48
model: mlp | iter: 2500 | loss: 13.48
model: mlp | iter: 2750 | loss: 13.47
model: mlp | iter: 3000 | loss: 13.47
model: mlp | iter: 3250 | loss: 13.47
model: mlp | iter: 3500 | loss: 13.47
model: mlp | iter: 3750 | loss: 13.47
model: mlp | iter: 4000 | loss: 13.47
model: mlp | iter: 4250 | loss: 13.47
model: mlp | iter: 4500 | loss: 13.47
model: mlp | iter: 4750 | loss: 13.47
training deep net... [11/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 147598.55 | apl: 11.71
building surrogate dataset...
training surrogate net... [11/12]
model: mlp | iter: 0 | loss: 121.36
model: mlp | iter: 250 | loss: 23.14
model: mlp | iter: 500 | loss: 11.92
model: mlp | iter: 750 | loss: 10.52
model: mlp | iter: 1000 | loss: 10.22
model: mlp | iter: 1250 | loss: 10.11
model: mlp | iter: 1500 | loss: 10.04
model: mlp | iter: 1750 | loss: 9.98
model: mlp | iter: 2000 | loss: 9.94
model: mlp | iter: 2250 | loss: 9.89
model: mlp | iter: 2500 | loss: 9.85
model: mlp | iter: 2750 | loss: 9.79
model: mlp | iter: 3000 | loss: 9.74
model: mlp | iter: 3250 | loss: 9.68
model: mlp | iter: 3500 | loss: 9.61
model: mlp | iter: 3750 | loss: 9.54
model: mlp | iter: 4000 | loss: 9.48
model: mlp | iter: 4250 | loss: 9.43
model: mlp | iter: 4500 | loss: 9.38
model: mlp | iter: 4750 | loss: 9.35
training deep net... [12/12], learning rate: 0.0010
model: gru | iter: 0 | loss: 140957.15 | apl: 9.03
building surrogate dataset...
training surrogate net... [12/12]
model: mlp | iter: 0 | loss: 79.91
model: mlp | iter: 250 | loss: 20.33
model: mlp | iter: 500 | loss: 16.85
model: mlp | iter: 750 | loss: 16.48
model: mlp | iter: 1000 | loss: 16.40
model: mlp | iter: 1250 | loss: 16.38
model: mlp | iter: 1500 | loss: 16.37
model: mlp | iter: 1750 | loss: 16.37
model: mlp | iter: 2000 | loss: 16.36
model: mlp | iter: 2250 | loss: 16.36
model: mlp | iter: 2500 | loss: 16.36
model: mlp | iter: 2750 | loss: 16.36
model: mlp | iter: 3000 | loss: 16.36
model: mlp | iter: 3250 | loss: 16.35
model: mlp | iter: 3500 | loss: 16.35
model: mlp | iter: 3750 | loss: 16.35
model: mlp | iter: 4000 | loss: 16.35
model: mlp | iter: 4250 | loss: 16.35
model: mlp | iter: 4500 | loss: 16.35
model: mlp | iter: 4750 | loss: 16.35
saved visualize pdf and model to ./trained_models
